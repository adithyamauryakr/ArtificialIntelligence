{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZsDvT4YjExG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0zvQcpakN-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA7BWRPu4OGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8e_rc94rQwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dimension = 100\n",
        "noise_shape = (latent_dimension,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeRpz0Vln8lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "input_size = np.prod(image_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9oObupdkR7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = (X_train.astype('float32') - 127.5) / 127.5\n",
        "X_test = (X_test.astype('float32') - 127.5) / 127.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiW3s0w8_HnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "X_test = np.expand_dims(X_test, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siwK6P7BkbF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1JuK6jDmEGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Flatten, Dense, Reshape, BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQiwRWj3o3Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = Sequential(name='discriminator')\n",
        "\n",
        "discriminator.add(Flatten(input_shape=image_shape))\n",
        "\n",
        "discriminator.add(Dense(1024))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "discriminator.add(Dense(512))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "discriminator.add(Dense(256))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoRsgeFhmOIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Sequential(name='generator')\n",
        "\n",
        "generator.add(Dense(256, input_shape=noise_shape))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(512))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(1024))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "generator.add(Dense(input_size, activation='tanh'))\n",
        "generator.add(Reshape(image_shape))\n",
        "\n",
        "generator.summary()\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BduzkW5t__e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_images = Input(shape=noise_shape)\n",
        "generated_images = generator(input_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErkNOr68pWsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable = False\n",
        "predictions = discriminator(generated_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DYRYp8uuRxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = Model(input_images, predictions, name='gan')\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2D-61_6-hGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "def plot_generated(number_of_samples=10, dim=(1, 10), figsize=(12, 2)):\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=(number_of_samples, latent_dimension))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(number_of_samples, image_shape[0], image_shape[1])\n",
        "\n",
        "    plot.figure(figsize=figsize)\n",
        "    for i in range(number_of_samples):\n",
        "        plot.subplot(dim[0], dim[1], i+1)\n",
        "        plot.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plot.axis('off')\n",
        "\n",
        "    plot.tight_layout()\n",
        "    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oUae4fWpmoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "def plot_loss(losses):\n",
        "\n",
        "    discriminator_loss = [v[0] for v in losses[\"discriminator\"]]\n",
        "    generator_loss = [v[0] for v in losses[\"generator\"]]\n",
        "    \n",
        "    plot.figure(figsize=(10,8))\n",
        "    plot.plot(discriminator_loss, label=\"Discriminator loss\")\n",
        "    plot.plot(generator_loss, label=\"Generator loss\")\n",
        "\n",
        "    plot.xlabel('Epochs')\n",
        "    plot.ylabel('Loss')\n",
        "\n",
        "    plot.legend()\n",
        "    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQmu84-mqLpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\"discriminator\":[], \"generator\":[]}\n",
        "\n",
        "def train(epochs, batch_size=128, plot_frequency=1):    \n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "       \n",
        "    for epoch in range(epochs):  \n",
        "\n",
        "        ##########################################################################################\n",
        "        # Train discriminator        \n",
        "        ##########################################################################################\n",
        "\n",
        "        # Select a random half batch of images\n",
        "        indices = np.random.randint(0, X_train.shape[0], size=half_batch)\n",
        "        images = X_train[indices]        \n",
        "\n",
        "        # Generate a half batch of images          \n",
        "        noise = np.random.normal(0, 1, size=(half_batch, latent_dimension))  \n",
        "        generated_images = generator.predict(noise)\n",
        "        \n",
        "        # Train discriminator\n",
        "        discriminator.trainable = True\n",
        "        discriminator_loss_real = discriminator.train_on_batch(images, np.ones((half_batch, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((half_batch, 1)))\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        ##########################################################################################\n",
        "\n",
        "\n",
        "        ##########################################################################################\n",
        "        # Train generator  \n",
        "        ##########################################################################################      \n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dimension))\n",
        "\n",
        "        # The generator wants the discriminator to label \n",
        "        # the generated samples as valid\n",
        "        valid_y = np.array([1] * batch_size)\n",
        "\n",
        "        # Train generator \n",
        "        discriminator.trainable = False\n",
        "        generator_loss = gan.train_on_batch(noise, valid_y)\n",
        "        ##########################################################################################        \n",
        "\n",
        "        if (epoch > 0)  and (epoch%plot_frequency == 0):\n",
        "            losses[\"discriminator\"].append(discriminator_loss)\n",
        "            losses[\"generator\"].append(generator_loss)\n",
        "            \n",
        "            plot_generated()\n",
        "\n",
        "    plot_loss(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bng4hrJ0xnqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(30000, batch_size=128, plot_frequency=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sequence_generation.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hr2SibbfIeP1","colab_type":"text"},"source":["# Sequence generation\n","In this assignment, we will utilize a recurrent neural network (RNN) for sequence generation. Here, we'll train RNNs to generate text character by character. We'll start from scratch, starting from loading the dataset to defining the model to it's training and then generating the text from the trained model.  \n","In this, we'll be covering the following subsections:\n","\n","\n","1. Import pre-requisite modules (standard library for python, keras, and google colab)\n","\n","2. Load the dataset  \n","\n","3. Preprocessing of the dataset\n","\n","4. Convert Sequential dataset to Supervised learning dataset format (input(X),output(y))  \n","\n","5. Normalize the dataset  \n","\n","6. Define hyperparameters  \n","\n","7. Define RNN model\n","\n","8. Compile the model\n","\n","9. Train the model\n","\n","10. Evaluate the model\n","\n","\n","Each subsection cell comes with a short description and instructions for carrying out the subtask in the immediate code cell. Some subsections will be complete and self-sufficient, you don't have to write module or code in that. Its' advised to go through each subsection concepts and what it implements throroughly.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"2H3aliXYknM0","colab_type":"text"},"source":["### Import Google colab drive helper module and mount the drive\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Nr8vupswkqbN","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","import os "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhIprIFiktmF","colab_type":"code","colab":{}},"source":["# mount your google drive into the google colab\n","drive.mount('/content/drive')\n","\n","# navigate to the folder path in your drive where keras utility files exist\n","current_path = '/content/drive/My Drive/rnn/keras/'\n","os.chdir(current_path)\n","\n","# list all files under that path\n","!ls -al"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zipJYNk0KA3T","colab_type":"text"},"source":["### Import required python and keras modules"]},{"cell_type":"code","metadata":{"id":"CThMTWltflv0","colab_type":"code","colab":{}},"source":["# python system and numpy modules\n","import sys\n","import numpy\n","\n","# keras modules\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.optimizers import Adam\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWOa-qzsm53u","colab_type":"text"},"source":["### Load the dataset\n","\n","*   Preprocessing of the dataset  \n","1. Load the text file. Look what the text contains. Next, convert the text file characters to lowercase characters.  \n","\n","2. Create an array of unique characters that occurs in the text file including all numbers and special characters. This array of unique characters is called ```vocabulary```.  \n","\n","3. Create two dictionaries namely ```character_to_identifier and identifier_to_character ```. Former maps each character to it's corresponding integer index  and latter maps each integer index to it's corresponding character by looking from the ```vocabulary``` array.  \n","\n","4. Print total characters length in the text data and length of the ```vocabulary``` array.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VBXmCMrtfp4F","colab_type":"code","colab":{}},"source":["# load text file into a variable - raw_text_data\n","filename = \"datasets/alice_in_wonderland.txt\"\n","raw_text_data = open(filename).read()\n","\n","# Look what the text is all about\n","\n","# convert all characters in raw_text_data into lowercase characters format\n","text_data = raw_text_data.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lK7BnjO4o1e1","colab_type":"code","colab":{}},"source":["# create an array of unique characters - vocabulary, which includes all type of characters\n","vocabulary = sorted(list(set(text_data)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VXbWSwktkHY","colab_type":"code","colab":{}},"source":["# create a dictionary - character_to_identifier, that has each character and it's corresponding index as a (key, value) pair\n","character_to_identifier = dict((character, identifier) for identifier, character in enumerate(vocabulary))\n","\n","# create a dictionary - indentifier_to_character, that has integer index and it's corresponding character as a (key, value) pair\n","identifier_to_character = dict((identifier, character) for identifier, character in enumerate(vocabulary))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fy-bHBI_qOmA","colab_type":"code","colab":{}},"source":["# print total number of characters in text_data and vocabulary array\n","total_characters = len(text_data)\n","vocabulary_length = len(vocabulary)\n","\n","print('Total characters - ', total_characters)\n","print('Total vocabulary_length - ', vocabulary_length)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xUxDxGZnRor","colab_type":"text"},"source":["### Convert sequence data into supervised learning dataset format"]},{"cell_type":"code","metadata":{"id":"sadHcSgCgATe","colab_type":"code","colab":{}},"source":["sequence_length = 100\n","\n","X_data = []\n","Y_data = []\n","\n","for i in range(0, total_characters - sequence_length, 1):\n","\tsequence_input = text_data[i:i + sequence_length]\n","\tsequence_output = text_data[i + sequence_length]\n","\tX_data.append([character_to_identifier[char] for char in sequence_input])\n","\tY_data.append(character_to_identifier[sequence_output])\n"," \n","number_of__patterns = len(X_data)\n","print('Total patterns - ', number_of__patterns)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOVVA4bKncCF","colab_type":"text"},"source":["### Normalize the dataset"]},{"cell_type":"code","metadata":{"id":"b_536DgLgILM","colab_type":"code","colab":{}},"source":["# reshape input sequence into 3-D tensor format\n","X = numpy.reshape(X_data, (number_of__patterns, sequence_length, 1))\n","\n","# normalize integer representation of input sequence by dividing with maximum integer i.e. vocabulary_length\n","X = X / float(vocabulary_length)\n","\n","# convert integer representation of output character (0-vocabulary_length) into one-hot vector of length=vocabulary_length\n","Y = np_utils.to_categorical(Y_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dWw-5E2jnpBp","colab_type":"text"},"source":["#### Define hyperparameters\n","\n","*   Create an object of Adam optimizer with learning rate  value 0.001.\n","*   Set epochs with value 1 and batch_size with value 256. Note that these parameters values are tunable and should try different values for training the model and chose only that value which gives good results. "]},{"cell_type":"code","metadata":{"id":"2jB3ox17np_N","colab_type":"code","colab":{}},"source":["# define optimizer\n","learning_rate = 0.0001\n","optimizer = Adam(lr=learning_rate)\n","\n","\n","# define other hyperparameters\n","epochs = 1\n","batch_size = 256"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caj_uXcinzP8","colab_type":"text"},"source":["### Define a simple recurrent neural network model using Keras.\n","\n","1. Create a sequential model. See [link](https://keras.io/models/sequential/) for details.\n","\n","2. Add a LSTM layer to the model. See [link](https://keras.io/layers/recurrent) for more details.\n","Set units = 256, input_shape = (X.shape[1], X.shape[2]) for the layer.\n","\n","3. Add a dropout layer to the model. See [link](https://keras.io/layers/core/) for details. Set a dropout rate = 0.2 for the layer.\n","\n","4. Add a dense layer to the model. See [link](https://keras.io/layers/core/) for details. Set units = y.shape[1], activation = softmax for the layer."]},{"cell_type":"code","metadata":{"id":"iJliL6aS2Xr2","colab_type":"code","colab":{}},"source":["# design a rnn based model\n","model = Sequential()\n","model.add(LSTM(units=256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units=256))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=Y.shape[1], activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YjgaqLvk12Kw","colab_type":"text"},"source":["### Compile the simple model\n","\n","1. See [link](https://keras.io/models/model/) for details.\n","\n","2. Set loss = categorical_crossentropy.\n","\n","3. Set optimizer=optimizer (created Adam optimizer).\n","\n","4. Set metrics = accuracy.\n","\n","5. Print model summary for visualization."]},{"cell_type":"code","metadata":{"id":"t4O1bD8316vD","colab_type":"code","colab":{}},"source":["# compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","\n","# visualize the model\n","print(model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsOUgheM2I2-","colab_type":"text"},"source":["### Train the model\n","\n","1. Set number of epochs between 1-10.\n","\n","2. Set batch size as multiple of 32 i.e. either 128 or 256.\n","\n","3.  Call function fit(...) on the model. \n","\n","4.  See [link](https://keras.io/models/model/) for details.\n","\n","5. Pass X and Y for training the model."]},{"cell_type":"code","metadata":{"id":"Klww5EU62wWD","colab_type":"code","colab":{}},"source":["model.fit(X, Y, epochs=epochs, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UK-KmCvQ2mNf","colab_type":"text"},"source":["### Evaluate the model\n","Since it takes time to train the model so we have already saved a trained model. We can use that trained model.  \n","1. Load weights of pre-trained model using ```load_weights``` function\n","\n","2. Extract a small input sequence from the input sequence (```X_data```), convert the extracted input sequence integer representation back to characters using ```identifier_to_character``` function.\n","\n","3. Define maximum characters that you want to produce/generate from the model.\n","\n","4. Start a loop that iterates for generating characters in sequence upto the maximum characters\n","\n","4. Reshape ```model_input```\n","\n","5. Predict next character in sequence using ```predict``` function\n","\n","6. Convert model output integer representation to it's corresponding character representation using ```character_to_identifier ``` function.\n","\n","7. Print generated character"]},{"cell_type":"code","metadata":{"id":"emQpVvacBlSk","colab_type":"code","colab":{}},"source":["# load previously trained model weights\n","filename = 'models/best_wonderland_model.hdf5'\n","model.load_weights(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6jXem1rBpR8","colab_type":"code","colab":{}},"source":["# create a random sequence of input characters for predicting next sequence of characters\n","start = numpy.random.randint(0, len(X_data)-1)\n","pattern = X_data[start]\n","print('Seed is -')\n","print('\\\"', ''.join([identifier_to_character[value] for value in pattern]), '\\\"')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mh_CskggpWCZ","colab_type":"code","colab":{}},"source":["# Create a loop for generating one character at a time using loaded model upto maximum_characters\n","maximum_characters = 500\n","for character in range(maximum_characters):\n","\tmodel_input = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tmodel_input = model_input / float(vocabulary_length)\n"," \n","\tprediction = model.predict(model_input, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tmodel_output = identifier_to_character[index]\n","\n","\tsys.stdout.write(model_output)\n"," \n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]"],"execution_count":0,"outputs":[]}]}
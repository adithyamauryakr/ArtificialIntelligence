{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn_sentiment_analysis.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hr2SibbfIeP1","colab_type":"text"},"source":["# Sentiment analysis\n","In this assignment, we will learn to create neural network model for [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) using [neural network](https://en.wikipedia.org/wiki/Neural_network) approach. "]},{"cell_type":"markdown","metadata":{"id":"2H3aliXYknM0","colab_type":"text"},"source":["### Import Google Colab drive helper and mount the Google drive."]},{"cell_type":"code","metadata":{"id":"Nr8vupswkqbN","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhIprIFiktmF","colab_type":"code","colab":{}},"source":["import os\n","\n","current_path = '/content/drive/My Drive/compare/keras/'\n","os.chdir(current_path)\n","\n","!ls -al"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FsED_4KnV2fD","colab_type":"text"},"source":["### Import required python modules."]},{"cell_type":"code","metadata":{"id":"CThMTWltflv0","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.random.seed(7)\n","\n","from keras.datasets import imdb"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zipJYNk0KA3T","colab_type":"text"},"source":["### Load the IMDb dataset.\n","\n","Keras has a built-in [IMDb movie reviews dataset](https://keras.io/datasets). We will use this dataset.\n","- Set vocabulary size = 5000.\n","- Set embedding size = 32.\n","- Load IMDb dataset.\n","\n","### Hints\n","- [IMDb movie reviews dataset](https://keras.io/datasets)"]},{"cell_type":"code","metadata":{"id":"VBXmCMrtfp4F","colab_type":"code","colab":{}},"source":["vocabulary_size = 5000\n","embedding_size = 32\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n","print('Loaded IMDB dataset with {} training samples and {} test samples.'.format(len(X_train), len(X_test)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_lrYTF_fz_J","colab_type":"code","colab":{}},"source":["sample_index = np.random.randint(0, X_train.shape[0])\n","\n","print('Review ', X_train[sample_index])\n","print('Label ', y_train[sample_index])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cTwM0Y6f2uu","colab_type":"code","colab":{}},"source":["word_to_identifier = imdb.get_word_index()\n","identifier_to_word = {i: word for word, i in word_to_identifier.items()}\n","\n","print('Review with words' , [identifier_to_word.get(i, ' ') for i in X_train[sample_index]])\n","print('Label ' , y_train[sample_index])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sadHcSgCgATe","colab_type":"code","colab":{}},"source":["print('Maximum review length: {}'.format(len(max((X_train + X_test), key=len))))\n","print('Minimum review length: {}'.format(len(min((X_test + X_test), key=len))))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlpY9soxLQIS","colab_type":"text"},"source":["### Pad sequences\n","\n","In order to feed this data into our neural network model, all input documents must have the same length. We will limit the maximum review length to max_words is equal to 500 by truncating longer reviews and padding shorter reviews with a null value (0). We can accomplish this using the [pad_sequences(...)](https://keras.io/preprocessing/sequence/) function in Keras. \n","\n","\n","### Hints\n","- [pad_sequences()](https://keras.io/preprocessing/sequence/)"]},{"cell_type":"code","metadata":{"id":"b_536DgLgILM","colab_type":"code","colab":{}},"source":["from keras.preprocessing import sequence\n","\n","max_words = 500\n","\n","X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n","X_test = sequence.pad_sequences(X_test, maxlen=max_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmkbSHgzaabt","colab_type":"code","colab":{}},"source":["validation_size = 1000\n","\n","X_val, y_val = X_train[:validation_size], y_train[:validation_size]\n","X_train, y_train = X_train[validation_size:], y_train[validation_size:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6ktTKxCZeL8","colab_type":"text"},"source":["### Use Adam optimizer.\n","\n","*   Import Adam optimizer from keras optimizers. See [link](https://keras.io/optimizers/) for details.\n","*   Create an object of Adam optimizer with learning rate  value 0.001."]},{"cell_type":"code","metadata":{"id":"F7XymosWZguY","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","\n","learning_rate = 0.001\n","optimizer = Adam(lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0bl-Pa0bnZm","colab_type":"text"},"source":["### Import required python modules."]},{"cell_type":"code","metadata":{"id":"AeT-oSq4bqbN","colab_type":"code","colab":{}},"source":["from helper_functions import *\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.embeddings import Embedding"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dcgg5vA1XdQN","colab_type":"text"},"source":["### Create a simple neural network model using Keras.\n","\n","1. Create a sequential model. See [link](https://keras.io/models/sequential/) for details.\n","\n","2. Add an embedding layer to the model. See [link](https://keras.io/layers/embeddings) for more details.\n","Set input_dim = vocabulary_size, output_dim = embedding_size and input_length = max_words.\n","\n","3. Add a flatten layer to the the model. See [link](https://keras.io/layers/core/) for details.\n","\n","4. Add a dense layer to the model. See [link](https://keras.io/layers/core/) for details. Set units = 64, activation = relu for the layer.\n","\n","5. Add a dense layer to the model. Set units = 1, activation = sigmoid for the layer."]},{"cell_type":"code","metadata":{"id":"Klww5EU62wWD","colab_type":"code","colab":{}},"source":["nn_model = Sequential()\n","nn_model.add(Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=max_words))\n","nn_model.add(Flatten())\n","nn_model.add(Dense(units=64, activation='relu'))\n","nn_model.add(Dense(units=1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGeR8MvcbZFp","colab_type":"text"},"source":["### Compile the simple neural network model.\n","\n","1. See [link](https://keras.io/models/model/) for details.\n","2. Set loss = binary_crossentropy.\n","3. Set optimizer=optimizer (created Adam optimizer).\n","4. Set metrics = accuracy.\n","5. Print model summary for visualization."]},{"cell_type":"code","metadata":{"id":"fd50doLNb7x3","colab_type":"code","colab":{}},"source":["nn_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","print(nn_model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i9ul4rFibzaI","colab_type":"text"},"source":["### Train the simple neural network model.\n","\n","1. Set number of epochs between 10-20.\n","2. Set batch size as multiple of 32 i.e. either 32 or 64.\n","3.  Call function fit(...) on the model. \n","4.  See [link](https://keras.io/models/model/) for details.\n","5. Pass X_train and y_train for training the model\n","6. Pass X_val and y_val as validation data."]},{"cell_type":"code","metadata":{"id":"kyOwShMHcCdP","colab_type":"code","colab":{}},"source":["num_epochs = 10\n","batch_size = 64"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDJ2xEQ9dwS7","colab_type":"code","colab":{}},"source":["history = nn_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=num_epochs)\n","show_graph(history)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DT-JRH1acOuX","colab_type":"text"},"source":["### Print the model accuracy."]},{"cell_type":"code","metadata":{"id":"6D5RTtEBcPMH","colab_type":"code","colab":{}},"source":["scores = nn_model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCb3UHFAeULn","colab_type":"text"},"source":["**Expected Output**:\n","\n","<table>\n","    <tr>\n","        <td>\n","            Test accuracy\n","        </td>\n","        <td>\n","           between 75.0 and 95.0\n","        </td>\n","    </tr>\n","</table>"]}]}
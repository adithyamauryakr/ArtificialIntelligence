{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenoiseDocuments.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/look4pritam/ArtificialIntelligence/blob/master/notebooks/CNN/Autoencoder/DenoiseDocuments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Vi_RFldc9V"
      },
      "source": [
        "# Denoising Dirty Documents\n",
        "\n",
        "Remove noise from printed text. See [link](https://www.kaggle.com/c/denoising-dirty-documents/) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExtT7EOj_X8D"
      },
      "source": [
        "import os\n",
        "\n",
        "root_dir = '/content/'\n",
        "os.chdir(root_dir)\n",
        "\n",
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06kdnfia_iPu"
      },
      "source": [
        "Create Kaggle API token.\n",
        "Upload the token 'kaggle.json' at '/content/' directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2QYNmtALLC"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = root_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "MINYol5yJ-B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMdwQD7PAlEl"
      },
      "source": [
        "!kaggle competitions download -c denoising-dirty-documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip denoising-dirty-documents.zip"
      ],
      "metadata": {
        "id": "Uh8roeIdKz_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9IQKXZkIke2"
      },
      "source": [
        "train = os.path.join(root_dir, 'train.zip')\n",
        "train_cleaned = os.path.join(root_dir, 'train_cleaned.zip')\n",
        "test = os.path.join(root_dir, 'test.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmrZ1l8jIk6g"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "\n",
        "def extract_zip_file(file_names):\n",
        "    for file in file_names:\n",
        "        with ZipFile(file, 'r') as zip: \n",
        "            zip.extractall() \n",
        "\n",
        "extract_zip_file([train, train_cleaned, test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqmNnNxKzqf"
      },
      "source": [
        "import glob\n",
        "\n",
        "train_images = sorted(glob.glob('train/*.png'))\n",
        "train_cleaned_images = sorted(glob.glob('train_cleaned/*.png'))\n",
        "test_images = sorted(glob.glob('test/*.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGkBi5d_MDt"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04bSC9KZLC9u"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
        "\n",
        "def convert_imgs_to_array(images_folder, test=False):\n",
        "    images = []\n",
        "    for img_dir in images_folder:\n",
        "        image = load_img(img_dir, color_mode='grayscale', target_size=(258, 540, 1))\n",
        "        image = img_to_array(image).astype('float32') / 255.0\n",
        "        images.append(image)\n",
        "    return np.asarray(images)\n",
        "\n",
        "X_train_full = convert_imgs_to_array(train_images)\n",
        "Y_train_full = convert_imgs_to_array(train_cleaned_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUxYg5EiAVNK"
      },
      "source": [
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_full, Y_train_full, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuClcgfFLuIW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
        "\n",
        "def build_autoenocder():\n",
        "    input_img = Input(shape=(None,None,1), name='image_input')\n",
        "    \n",
        "    #enoder \n",
        "    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n",
        "    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n",
        "    \n",
        "    #decoder\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)\n",
        "    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv4')(x)\n",
        "    x = UpSampling2D((2,2), name='upsample2')(x)\n",
        "    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)\n",
        "    \n",
        "    #model\n",
        "    autoencoder = Model(inputs=input_img, outputs=x)\n",
        "    return autoencoder\n",
        "\n",
        "model = build_autoenocder()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyFBjiKyAq-F"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQiDLgrSMY6o"
      },
      "source": [
        "K = keras.callbacks\n",
        "reduce_lr = K.ReduceLROnPlateau(monitor='val_mae', patience=7, verbose=1, factor=0.1, min_lr=0.00001)\n",
        "early_stopping = K.EarlyStopping(monitor='val_mae', patience=20, restore_best_weights=True, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcYZMXNMmOF"
      },
      "source": [
        "epochs = 500\n",
        "batch_size = 2\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
        "                   batch_size=batch_size, epochs=epochs, shuffle=True,\n",
        "                   callbacks=[reduce_lr, early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9haISXdT_Ors"
      },
      "source": [
        "val_loss, val_mae = model.evaluate(X_val, Y_val, verbose=1)\n",
        "print(\"Validation loss: {0:.4f} and mae: {1:.4f}\".format(val_loss, val_mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrQ_WQAi5acp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import cv2\n",
        "\n",
        "def plot_documents_after_training(nrows=3, ncols=2):\n",
        "    selection = np.random.choice(len(test_images), size=(nrows*ncols), replace=False)\n",
        "    images = np.asarray(test_images)[selection]\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=(nrows*20, ncols*30), nrows=nrows, ncols=ncols)\n",
        "    fig.subplots_adjust(hspace=.05, wspace=.05)\n",
        "    axes = axes.ravel()\n",
        "    for img, i in zip(images, range(0, nrows*ncols, 2)):\n",
        "        original_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "        img = load_img(img, color_mode='grayscale', target_size=(original_img.shape[0], original_img.shape[1], 1))\n",
        "        img = img_to_array(img).astype('float32') / 255.0\n",
        "        predicted_img = model.predict(np.expand_dims(img, axis=0))\n",
        "        axes[i].imshow(array_to_img(img), cmap='gray')\n",
        "        axes[i+1].imshow(array_to_img(predicted_img[0]), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i+1].axis('off')\n",
        "        \n",
        "plot_documents_after_training()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
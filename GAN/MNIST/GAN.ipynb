{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GAN.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb","timestamp":1586841538329}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FJ2RLI6tJ--2","colab_type":"code","colab":{}},"source":["!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n","!apt-get update\n","!apt-get install cuda=9.0.176-1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AtT63xslnNE","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","!pip uninstall tensorflow -y\n","!pip install --upgrade tensorflow-gpu==1.12.2 \n","!pip install --upgrade keras==2.2.4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZsDvT4YjExG","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","from keras.datasets import mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0zvQcpakN-M","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.random.seed(7)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qVo3rnMjnHb","colab_type":"code","colab":{}},"source":["input_size = np.prod(X_train.shape[1:])\n","number_of_training_samples = len(X_train)\n","number_of_testing_samples = len(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9oObupdkR7r","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(number_of_training_samples, input_size)\n","X_test = X_test.reshape(number_of_testing_samples, input_size)\n","\n","X_train = X_train.astype('float32') / 127.5 - 1.\n","X_test = X_test.astype('float32') / 127.5 - 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"siwK6P7BkbF-","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","\n","optimizer = Adam(lr=0.0002, beta_1=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1JuK6jDmEGK","colab_type":"code","colab":{}},"source":["from keras.layers import Input, Dense, BatchNormalization\n","from keras.models import Sequential, Model\n","\n","from keras.layers.advanced_activations import LeakyReLU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoRsgeFhmOIi","colab_type":"code","colab":{}},"source":["latent_dimension = 100\n","\n","generator = Sequential()\n","\n","generator.add(Dense(256, input_dim=latent_dimension))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(512))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(alpha=0.2))\n","generator.add(BatchNormalization(momentum=0.8))\n","\n","generator.add(Dense(input_size, activation='tanh'))\n","generator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQiwRWj3o3Bh","colab_type":"code","colab":{}},"source":["discriminator = Sequential()\n","\n","discriminator.add(Dense(1024, input_dim=input_size,))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","\n","discriminator.add(Dense(512))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","\n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(alpha=0.2))\n","\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ErkNOr68pWsp","colab_type":"code","colab":{}},"source":["discriminator.trainable = False\n","input_images = Input(shape=(latent_dimension, ))\n","generated_images = generator(input_images)\n","predictions = discriminator(generated_images)\n","gan = Model(input_images, predictions)\n","gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oUae4fWpmoK","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plot\n","\n","def plot_loss(losses):\n","\n","    discriminator_loss = [v[0] for v in losses[\"discriminator\"]]\n","    generator_loss = [v[0] for v in losses[\"generator\"]]\n","    \n","    plot.figure(figsize=(10,8))\n","    plot.plot(discriminator_loss, label=\"Discriminator loss\")\n","    plot.plot(generator_loss, label=\"Generator loss\")\n","\n","    plot.xlabel('Epochs')\n","    plot.ylabel('Loss')\n","\n","    plot.legend()\n","    plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZspOQdkp4mZ","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plot\n","\n","def plot_generated(number_of_samples=10, dim=(1, 10), figsize=(12, 2)):\n","\n","    noise = np.random.normal(0, 1, size=(number_of_samples, latent_dimension))\n","    generated_images = generator.predict(noise)\n","    generated_images = generated_images.reshape(number_of_samples, 28, 28)\n","\n","    plot.figure(figsize=figsize)\n","    for i in range(number_of_samples):\n","        plot.subplot(dim[0], dim[1], i+1)\n","        plot.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n","        plot.axis('off')\n","\n","    plot.tight_layout()\n","    plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQmu84-mqLpb","colab_type":"code","colab":{}},"source":["from tqdm import tqdm_notebook\n","\n","losses = {\"discriminator\":[], \"generator\":[]}\n","\n","def train(epochs=1, plot_frequency=1, batch_size=128):\n","    batch_count = int(X_train.shape[0] / batch_size)\n","\n","    print('Epochs:', epochs)\n","    print('Batch size:', batch_size)\n","    print('Batches per epoch:', batch_count)\n","    \n","    for epoch in tqdm_notebook(range(1, epochs+1)):\n","\n","        if (epoch == 1) or (epoch % plot_frequency == 0):\n","            print('-'*15, 'Epoch %d' % epoch, '-'*15)\n","            \n","        for _ in range(batch_count):\n","\n","            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n","\n","            noise = np.random.normal(0, 1, size=(batch_size, latent_dimension))            \n","            generated_images = generator.predict(noise)\n","\n","            X = np.concatenate((image_batch, generated_images))\n","\n","            y = np.zeros(2*batch_size)\n","            y[:batch_size] = 0.9\n","\n","            discriminator.trainable = True\n","            discriminator_loss = discriminator.train_on_batch(X, y)\n","\n","            noise = np.random.normal(0, 1, size=(batch_size, latent_dimension))\n","            y2 = np.ones(batch_size)\n","\n","            discriminator.trainable = False\n","            generator_loss = gan.train_on_batch(noise, y2)\n","\n","        losses[\"discriminator\"].append(discriminator_loss)\n","        losses[\"generator\"].append(generator_loss)\n","\n","        if ( epoch == 1 ) or (epoch%plot_frequency == 0):\n","            plot_generated()\n","\n","    plot_loss(losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bng4hrJ0xnqB","colab_type":"code","colab":{}},"source":["train(epochs=200, plot_frequency=20, batch_size=128)"],"execution_count":0,"outputs":[]}]}
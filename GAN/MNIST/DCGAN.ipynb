{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DCGAN.ipynb","provenance":[{"file_id":"https://github.com/look4pritam/TensorFlowExamples/blob/master/GAN/MNIST/GAN.ipynb","timestamp":1588309181188},{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb","timestamp":1586841538329}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"A8Ufe_yYnNFe","colab_type":"code","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZsDvT4YjExG","colab_type":"code","colab":{}},"source":["try:\n","  %tensorflow_version 1.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0zvQcpakN-M","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.random.seed(7)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nA7BWRPu4OGk","colab_type":"code","colab":{}},"source":["from keras.datasets import mnist\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8e_rc94rQwm","colab_type":"code","colab":{}},"source":["latent_dimension = 100\n","noise_shape = (latent_dimension,)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeRpz0Vln8lO","colab_type":"code","colab":{}},"source":["image_shape = (X_train.shape[1], X_train.shape[2], 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzkufxQ54L-l","colab_type":"code","colab":{}},"source":["print(X_train.shape, X_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9oObupdkR7r","colab_type":"code","colab":{}},"source":["X_train = (X_train.astype('float32') - 127.5) / 127.5\n","X_test = (X_test.astype('float32') - 127.5) / 127.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TiW3s0w8_HnP","colab_type":"code","colab":{}},"source":["X_train = np.expand_dims(X_train, axis=3)\n","X_test = np.expand_dims(X_test, axis=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7Xfli5j36Jv","colab_type":"code","colab":{}},"source":["print(X_train.shape, X_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"siwK6P7BkbF-","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","\n","optimizer = Adam(lr=0.0001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pUo7-s35tIT","colab_type":"code","colab":{}},"source":["from keras.optimizers import SGD\n","\n","optimizer = SGD(lr=0.0005, momentum=0.9, nesterov=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1JuK6jDmEGK","colab_type":"code","colab":{}},"source":["from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\n","from keras.layers import Dropout, Flatten, Reshape, BatchNormalization\n","\n","from keras.layers.core import Activation\n","\n","from keras.models import Sequential, Model\n","\n","from keras.layers.advanced_activations import LeakyReLU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQiwRWj3o3Bh","colab_type":"code","colab":{}},"source":["discriminator = Sequential(name='discriminator')\n","\n","discriminator.add(Conv2D(64, (5, 5), padding='same', input_shape=image_shape))\n","discriminator.add(Activation('tanh'))\n","discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","discriminator.add(Conv2D(128, (5, 5)))\n","discriminator.add(Activation('tanh'))\n","discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","discriminator.add(Flatten())\n","\n","discriminator.add(Dense(1024))\n","discriminator.add(Activation('tanh'))\n","\n","discriminator.add(Dense(1))\n","discriminator.add(Activation('sigmoid'))\n","\n","discriminator.summary()\n","\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5BmIv-gPSsQ","colab_type":"code","colab":{}},"source":["generator_shape = (7, 7, 128)\n","generator_size = np.prod(generator_shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoRsgeFhmOIi","colab_type":"code","colab":{}},"source":["generator = Sequential(name='generator')\n","\n","generator.add(Dense(1024, input_shape=noise_shape))    \n","generator.add(Activation('tanh'))\n","\n","generator.add(Dense(generator_size))    \n","generator.add(BatchNormalization())\n","generator.add(Activation('tanh'))\n","\n","generator.add(Reshape(generator_shape))\n","\n","generator.add(UpSampling2D(size=(2, 2)))\n","generator.add(Conv2D(64, (5, 5), padding='same'))\n","generator.add(Activation('tanh'))\n","\n","generator.add(UpSampling2D(size=(2, 2)))\n","generator.add(Conv2D(1, (5, 5), padding='same'))\n","generator.add(Activation('tanh'))\n","\n","generator.summary()\n","\n","generator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJBXKh1282Gu","colab_type":"code","colab":{}},"source":["gan = Sequential(name='gan')\n","gan.add(generator)\n","discriminator.trainable = False\n","gan.add(discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2D-61_6-hGf","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plot\n","\n","def plot_generated(number_of_samples=10, dim=(1, 10), figsize=(12, 2)):\n","\n","    noise = np.random.uniform(-1, 1, size=(number_of_samples, latent_dimension))\n","    generated_images = generator.predict(noise)\n","    generated_images = generated_images*127.5 + 127.5\n","    generated_images = generated_images.reshape(number_of_samples, image_shape[0], image_shape[1])\n","\n","    plot.figure(figsize=figsize)\n","    for i in range(number_of_samples):\n","        plot.subplot(dim[0], dim[1], i+1)\n","        plot.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n","        plot.axis('off')\n","\n","    plot.tight_layout()\n","    plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oUae4fWpmoK","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plot\n","\n","def plot_loss(losses):\n","\n","    discriminator_loss = [v[0] for v in losses[\"discriminator\"]]\n","    generator_loss = [v[0] for v in losses[\"generator\"]]\n","    \n","    plot.figure(figsize=(10,8))\n","    plot.plot(discriminator_loss, label=\"Discriminator loss\")\n","    plot.plot(generator_loss, label=\"Generator loss\")\n","\n","    plot.xlabel('Epochs')\n","    plot.ylabel('Loss')\n","\n","    plot.legend()\n","    plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQmu84-mqLpb","colab_type":"code","colab":{}},"source":["losses = {\"discriminator\":[], \"generator\":[]}\n","\n","def train(epochs, batch_size=128, plot_frequency=1):    \n","\n","    half_batch = int(batch_size / 2)\n","       \n","    for epoch in range(epochs):  \n","\n","        ##########################################################################################\n","        # Train discriminator        \n","        ##########################################################################################\n","\n","        # Select a random half batch of images\n","        indices = np.random.randint(0, X_train.shape[0], size=half_batch)\n","        images = X_train[indices]        \n","\n","        # Generate a half batch of images          \n","        noise = np.random.uniform(-1, 1, size=(half_batch, latent_dimension))  \n","        generated_images = generator.predict(noise)\n","        \n","        # Train discriminator\n","        discriminator.trainable = True\n","        discriminator_loss_real = discriminator.train_on_batch(images, np.ones((half_batch, 1)))\n","        discriminator_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((half_batch, 1)))\n","        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n","        ##########################################################################################\n","\n","\n","        ##########################################################################################\n","        # Train generator  \n","        ##########################################################################################      \n","\n","        noise = np.random.normal(0, 1, (batch_size, latent_dimension))\n","\n","        # The generator wants the discriminator to label \n","        # the generated samples as valid\n","        valid_y = np.array([1] * batch_size)\n","\n","        # Train generator \n","        discriminator.trainable = False\n","        generator_loss = gan.train_on_batch(noise, valid_y)\n","        ##########################################################################################        \n","\n","        if (epoch > 0)  and (epoch%plot_frequency == 0):\n","            losses[\"discriminator\"].append(discriminator_loss)\n","            losses[\"generator\"].append(generator_loss)\n","            \n","            plot_generated()\n","\n","    plot_loss(losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bng4hrJ0xnqB","colab_type":"code","colab":{}},"source":["train(30000, batch_size=128, plot_frequency=200)"],"execution_count":0,"outputs":[]}]}
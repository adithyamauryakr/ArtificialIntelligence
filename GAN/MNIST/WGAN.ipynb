{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN.ipynb","provenance":[{"file_id":"https://github.com/look4pritam/TensorFlowExamples/blob/master/GAN/MNIST/WGAN.ipynb","timestamp":1591021560225}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O3EGiJRQWlej","colab_type":"text"},"source":["# WGAN - Wasserstein Generative Adversarial Network"]},{"cell_type":"markdown","metadata":{"id":"_U3aklo5XhDq","colab_type":"text"},"source":["# Import TensorFlow 2.x."]},{"cell_type":"code","metadata":{"id":"_Q5RJ8t9XiCZ","colab_type":"code","colab":{}},"source":["try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","tf.random.set_seed(7)\n","\n","import tensorflow.keras.layers as layers\n","import tensorflow.keras.models as models\n","\n","import numpy as np\n","np.random.seed(7)\n","\n","import matplotlib.pyplot as plot\n","\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rahrGYU6SN9w","colab_type":"text"},"source":["# Clip model weights to a given hypercube."]},{"cell_type":"code","metadata":{"id":"PBROLEHOSe5-","colab_type":"code","colab":{}},"source":["from tf.keras.constraints import Constraint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"88dCXormSOWT","colab_type":"code","colab":{}},"source":["class ClipConstraint(Constraint):\t\n","\tdef __init__(self, clip_value):\n","\t\tself._clip_value = clip_value\n","\n","\tdef __call__(self, weights):\n","\t\treturn tf.keras.backend.clip(weights, -self._clip_value, self._clip_value)\n","\n","\tdef get_config(self):\n","\t\treturn {'clip_value': self._clip_value}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z8LKiIADS66p","colab_type":"text"},"source":["# Compute Wasserstein loss."]},{"cell_type":"code","metadata":{"id":"i02xrCLxS7Qi","colab_type":"code","colab":{}},"source":["def wasserstein_loss(y_true, y_pred):\n","\treturn tf.keras.backend.mean(y_true * y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ir-Xw-uKTbMb","colab_type":"text"},"source":["# Create the critic model."]},{"cell_type":"code","metadata":{"id":"cKuxSqHJTbfd","colab_type":"code","colab":{}},"source":["def create_critic_model(input_shape=(28,28,1)):\n","\n","\tinitializer = tf.keras.initializers.RandomNormal(stddev=0.02)\n","\tconstraint = ClipConstraint(0.01)\n"," \n","\tmodel = tf.keras.Models.Sequential()\n"," \n","\tmodel.add(layers.Conv2D(64, (4,4), strides=(2,2), \n","                         padding='same', \n","                         kernel_initializer=initializer, kernel_constraint=constraint, \n","                         input_shape=input_shape))\n","\tmodel.add(layers.BatchNormalization())\n","\tmodel.add(layers.LeakyReLU(alpha=0.2))\n"," \n","\tmodel.add(layers.Conv2D(64, (4,4), strides=(2,2), \n","                         padding='same', \n","                         kernel_initializer=initializer, kernel_constraint=constraint))\n","\tmodel.add(layers.BatchNormalization())\n","\tmodel.add(layers.LeakyReLU(alpha=0.2))\n"," \n","\tmodel.add(layers.Flatten())\n","\tmodel.add(layers.Dense(1))\n"," \n","\toptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n","\tmodel.compile(loss=wasserstein_loss, optimizer=optimizer)\n"," \n","\treturn(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5waeQ3fuUHhV","colab_type":"code","colab":{}},"source":["input_shape = (28,28,1)\n","critic_model = create_critic_model(input_shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M1aa6_5LVHPJ","colab_type":"text"},"source":["# Create the generator model."]},{"cell_type":"code","metadata":{"id":"viqB-Ng4VHlw","colab_type":"code","colab":{}},"source":["def create_generator_model(latent_dimension=50):\n","\tinitializer = tf.keras.initializers.RandomNormal(stddev=0.02)\n","\n","\tmodel = tf.keras.models.Sequential()\n","\n","\tnumber_of_nodes = 128 * 7 * 7\n","\n","\tmodel.add(layers.Dense(number_of_nodes, kernel_initializer=initializer, input_dim=latent_dimension))\n","\tmodel.add(layers.LeakyReLU(alpha=0.2))\n","\tmodel.add(layers.Reshape((7, 7, 128)))\n"," \n","\tmodel.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer))\n","\tmodel.add(layers.BatchNormalization())\n","\tmodel.add(layers.LeakyReLU(alpha=0.2))\n"," \n","\tmodel.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer))\n","\tmodel.add(layers.BatchNormalization())\n","\tmodel.add(layers.LeakyReLU(alpha=0.2))\n"," \n","\tmodel.add(layers.Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=initializer))\n","\treturn(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fe4FHyhVVa3O","colab_type":"text"},"source":["### Define the size of the latent space."]},{"cell_type":"code","metadata":{"id":"Eut1wSeVWJjc","colab_type":"code","colab":{}},"source":["latent_dimension = 50\n","generator_model = create_generator_model(latent_dimension)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_EbkO43WvUK","colab_type":"text"},"source":["# Create the GAN model.\n","* Combine the generator and the critic models.\n","* Use for updating the generator model."]},{"cell_type":"code","metadata":{"id":"kM8A42PxWvpO","colab_type":"code","colab":{}},"source":["def create_gan_model(generator, critic):\t\n","\tcritic.trainable = False\n","\n","\tmodel = tf.keras.models.Sequential()\n"," \n","\tmodel.add(generator)\n","\tmodel.add(critic)\n","\n","\toptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005) \n","\tmodel.compile(loss=wasserstein_loss, optimizer=optimizer) \n","\treturn(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lm7XTEnoYWiG","colab_type":"code","colab":{}},"source":["gan_model = define_gan(generator_model, critic_model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pbYLLtUNYjoH","colab_type":"text"},"source":["# Load dataset."]},{"cell_type":"markdown","metadata":{"id":"VAyl5HTtZE6f","colab_type":"text"},"source":["### Load real samples."]},{"cell_type":"code","metadata":{"id":"bnVxAntFZgXA","colab_type":"code","colab":{}},"source":["from keras.datasets.mnist import load_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9yzUqBATYj8t","colab_type":"code","colab":{}},"source":["def load_real_samples():\n","\n","\t(trainX, trainy), (_, _) = load_data()\n","\tselected_ix = trainy == 7\n","\tX = trainX[selected_ix]\n","\n","\tX = tf.expand_dims(X, axis=-1) \n","  X = tf.constant(X, dtype=tf.float32)\n","\tX = (X - 127.5) / 127.5\n","\n","\treturn( X )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"flP2edoGZljW","colab_type":"text"},"source":["### Generate real samples."]},{"cell_type":"code","metadata":{"id":"WQRtq4tzZl6R","colab_type":"code","colab":{}},"source":["def generate_real_samples(dataset, number_of_samples):\n","\t# choose random instances\n","\tix = randint(0, dataset.shape[0], number_of_samples)\n","\t# select images\n","\tX = dataset[ix]\n","\t# generate class labels, -1 for 'real'\n","\ty = -ones((number_of_samples, 1))\n","\treturn X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7vfWFK4kaFg1","colab_type":"text"},"source":["### Generate points in latent space as input for the generator."]},{"cell_type":"code","metadata":{"id":"6fs9BD1iaF1R","colab_type":"code","colab":{}},"source":["def generate_latent_points(latent_dimension, number_of_samples):\n","\tx_input = np.random.randn(latent_dimension * number_of_samples)\n","\tx_input = x_input.reshape(number_of_samples, latent_dimension)\n","\treturn(x_input)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dDwy4McmalEt","colab_type":"text"},"source":["### Generate fake samples with class labels using the generator."]},{"cell_type":"code","metadata":{"id":"zkTx83RMalY_","colab_type":"code","colab":{}},"source":["def generate_fake_samples(generator, latent_dimension, number_of_samples):\n","\tx_input = generate_latent_points(latent_dimension, number_of_samples)\n","\tX = generator.predict(x_input)\n","\ty = ones((number_of_samples, 1))\n","\treturn(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLVJ1_Jhbxob","colab_type":"text"},"source":["# Create the graph."]},{"cell_type":"code","metadata":{"id":"DqivyJotbx9R","colab_type":"code","colab":{}},"source":["def plot_graph(critic_real_history, critic_fake_history, generator_history):\n","\tpyplot.plot(critic_real_history, label='critic real')\n","\tpyplot.plot(critic_fake_history, label='critic fake')\n","\tpyplot.plot(generator_history, label='generator')\n","\tpyplot.legend()\t\n","\tpyplot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKNALqMdWT9g","colab_type":"code","colab":{}},"source":["from numpy import mean\n","from numpy import ones\n","from numpy.random import randint\n","\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, g_model, latent_dimension, number_of_samples=100):\n","\t# prepare fake examples\n","\tX, _ = generate_fake_samples(g_model, latent_dimension, number_of_samples)\n","\t# scale from [-1,1] to [0,1]\n","\tX = (X + 1) / 2.0\n","\t# plot images\n","\tfor i in range(10 * 10):\n","\t\t# define subplot\n","\t\tpyplot.subplot(10, 10, 1 + i)\n","\t\t# turn off axis\n","\t\tpyplot.axis('off')\n","\t\t# plot raw pixel data\n","\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n","\t# save plot to file\n","\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n","\tpyplot.savefig(filename1)\n","\tpyplot.close()\n","\t# save the generator model\n","\tfilename2 = 'model_%04d.h5' % (step+1)\n","\tg_model.save(filename2)\n","\tprint('>Saved: %s and %s' % (filename1, filename2))\n","\n","# train the generator and critic\n","def train(g_model, c_model, gan_model, dataset, latent_dimension, n_epochs=10, n_batch=64, n_critic=5):\n","\t# calculate the number of batches per training epoch\n","\tbat_per_epo = int(dataset.shape[0] / n_batch)\n","\t# calculate the number of training iterations\n","\tn_steps = bat_per_epo * n_epochs\n","\t# calculate the size of half a batch of samples\n","\thalf_batch = int(n_batch / 2)\n","\t# lists for keeping track of loss\n","\tc1_hist, c2_hist, g_hist = list(), list(), list()\n","\t# manually enumerate epochs\n","\tfor i in range(n_steps):\n","\t\t# update the critic more than the generator\n","\t\tc1_tmp, c2_tmp = list(), list()\n","\t\tfor _ in range(n_critic):\n","\t\t\t# get randomly selected 'real' samples\n","\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t\t# update critic model weights\n","\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\n","\t\t\tc1_tmp.append(c_loss1)\n","\t\t\t# generate 'fake' examples\n","\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dimension, half_batch)\n","\t\t\t# update critic model weights\n","\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n","\t\t\tc2_tmp.append(c_loss2)\n","\t\t# store critic loss\n","\t\tc1_hist.append(mean(c1_tmp))\n","\t\tc2_hist.append(mean(c2_tmp))\n","\t\t# prepare points in latent space as input for the generator\n","\t\tX_gan = generate_latent_points(latent_dimension, n_batch)\n","\t\t# create inverted labels for the fake samples\n","\t\ty_gan = -ones((n_batch, 1))\n","\t\t# update the generator via the critic's error\n","\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n","\t\tg_hist.append(g_loss)\n","\t\t# summarize loss on this batch\n","\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n","\t\t# evaluate the model performance every 'epoch'\n","\t\tif (i+1) % bat_per_epo == 0:\n","\t\t\tsummarize_performance(i, g_model, latent_dimension)\n","\t# line plots of loss\n","\tplot_history(c1_hist, c2_hist, g_hist)\n","\n","\n","# load image data\n","dataset = load_real_samples()\n","print(dataset.shape)\n","# train model\n","train(generator, critic, gan_model, dataset, latent_dimension)"],"execution_count":0,"outputs":[]}]}
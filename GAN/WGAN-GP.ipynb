{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN-GP.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPpiLgIEqY9Ht5luZaBDUBo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kW3BFZm8yyW7","colab_type":"text"},"source":["# WGAN-GP"]},{"cell_type":"markdown","metadata":{"id":"6r2qOV8ry51t","colab_type":"text"},"source":["# Import TensorFlow 2.x."]},{"cell_type":"code","metadata":{"id":"R1RyR-BZygQX","colab_type":"code","colab":{}},"source":["try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","tf.random.set_seed(7)\n","\n","import tensorflow.keras.layers as layers\n","import tensorflow.keras.models as models\n","\n","import numpy as np\n","np.random.seed(7)\n","\n","import matplotlib.pyplot as plot\n","\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"psPniUEzzDDs","colab_type":"text"},"source":["# Set the root directory."]},{"cell_type":"code","metadata":{"id":"mjnfjZVLzDxI","colab_type":"code","colab":{}},"source":["import os\n","\n","root_dir = '/content/'\n","os.chdir(root_dir)\n","\n","!ls -al"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hM_YzdyCKivQ","colab_type":"code","colab":{}},"source":["class Tanh(layers.Layer):\n","    def __init__(self):\n","        super(Tanh, self).__init__()\n","\n","    def call(self, inputs):\n","        return tf.keras.activations.tanh(inputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mW_JyB4Kz3bb","colab_type":"code","colab":{}},"source":["class Conv2D(layers.Layer):\n","  def __init__(self, filters, kernel_size, strides=2):\n","    super(Conv2D, self).__init__()\n","    self.conv_op = layers.Conv2D(filters = filters,\n","                                 kernel_size = kernel_size, \n","                                 strides = strides,\n","                                 padding = 'same', \n","                                 kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev=0.02),\n","                                 use_bias=True, \n","                                 bias_initializer=tf.keras.initializers.Constant(value=0.0))\n","  def call(self, inputs):\n","    return self.conv_op(inputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDs-raGsz7Wx","colab_type":"code","colab":{}},"source":["class BatchNorm(layers.Layer):\n","    def __init__(self, is_training=False):\n","        super(BatchNorm, self).__init__()\n","        self.bn = tf.keras.layers.BatchNormalization(epsilon=1e-5,\n","                                                     momentum=0.9,\n","                                                     scale=True,\n","                                                     trainable=is_training)\n","\n","    def call(self, inputs, training):\n","        x = self.bn(inputs, training=training)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEJzzHL5z-bn","colab_type":"code","colab":{}},"source":["class DenseLayer(layers.Layer):\n","    def __init__(self, hidden_n, is_input=False):\n","        super(DenseLayer, self).__init__()\n","\n","        self.fc_op = layers.Dense(hidden_n,\n","                                  kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02),\n","                                  bias_initializer=tf.keras.initializers.Constant(value=0.0))\n","\n","    def call(self, inputs):\n","        x = self.fc_op(inputs)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHD-0ClI0B1B","colab_type":"code","colab":{}},"source":["class UpConv2D(layers.Layer):\n","    def __init__(self, filters, kernel_size, strides):\n","        super(UpConv2D, self).__init__()\n","        self.up_conv_op = layers.Conv2DTranspose(filters,\n","                                                 kernel_size=kernel_size,\n","                                                 strides=strides,\n","                                                 padding='same',\n","                                                 kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02),\n","                                                 use_bias=True,\n","                                                 bias_initializer=tf.keras.initializers.Constant(value=0.0))\n","\n","    def call(self, inputs):\n","        x = self.up_conv_op(inputs)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieja4kUH0GyV","colab_type":"code","colab":{}},"source":["def create_discriminator_model(is_training):\n","  model = tf.keras.Sequential()\n","  model.add(Conv2D(64,4,2))\n","  model.add(layers.LeakyReLU(alpha=0.2))\n","\n","  model.add(Conv2D(128,4,2))\n","  model.add(BatchNorm(is_training=is_training))\n","  model.add(layers.LeakyReLU(alpha=0.2))\n","\n","  model.add(layers.Flatten())\n","\n","  model.add(DenseLayer(1024))\n","  model.add(BatchNorm(is_training=is_training))\n","  model.add(layers.LeakyReLU(alpha=0.2))\n","        \n","  model.add(DenseLayer(1))\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxGYQctU0Z9U","colab_type":"code","colab":{}},"source":["def create_generator_model(z_dim, is_training):\n","  model = tf.keras.Sequential()\n","\n","  model.add(DenseLayer(1024))\n","  model.add(BatchNorm(is_training=is_training))\n","  model.add(layers.ReLU())\n","\n","  model.add(DenseLayer(128*7*7))\n","  model.add(BatchNorm(is_training=is_training))\n","  model.add(layers.ReLU())\n","\n","  model.add(layers.Reshape((7,7,128)))\n","\n","  model.add(UpConv2D(64,4,2))\n","  model.add(BatchNorm(is_training=is_training))\n","  model.add(layers.ReLU())\n","\n","  model.add(UpConv2D(1,4,2))\n","  model.add(Tanh())\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXgyzdaeIyke","colab_type":"code","colab":{}},"source":["batch_size = 64\n","learnning_rate = 2e-4\n","z_dim = 62\n","lam = 10.\n","epochs =20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_miBvD13KJ8-","colab_type":"code","colab":{}},"source":["generator = create_generator_model(z_dim, is_training=True)\n","discriminator = create_discriminator_model(is_training=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wa_dI24FHFg8","colab_type":"code","colab":{}},"source":["generator_optimizer = tf.keras.optimizers.RMSprop(lr=5*learnning_rate)\n","discriminator_optimizer = tf.keras.optimizers.RMSprop(lr=learnning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHciCAxj2d0C","colab_type":"code","colab":{}},"source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n","BUFFER_SIZE=train_images.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DspTPpOK3m7-","colab_type":"code","colab":{}},"source":["train_images = (train_images-127.5)/127.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMgh3Slj3rlp","colab_type":"code","colab":{}},"source":["train_labels=tf.one_hot(train_labels,depth=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"McuoM2Zl3v5D","colab_type":"code","colab":{}},"source":["train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(batch_size,drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVWGraKM4Aqg","colab_type":"code","colab":{}},"source":["start_epoch=0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJ-zfcVI4QLp","colab_type":"code","colab":{}},"source":["def train_one_step(batch_images):\n","        batch_z = np.random.uniform(-1, 1,[batch_size, z_dim]).astype(np.float32)\n","        real_images = batch_images\n","        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n","            fake_images = generator(batch_z, training=True)\n","            fake_predictions = discriminator(fake_images, training=True)\n","            real_predictions = discriminator(real_images, training=True)\n","\n","            discriminator_loss = tf.reduce_mean(-real_predictions) + tf.reduce_mean(fake_predictions)\n","            generator_loss = tf.reduce_mean(-fake_predictions)\n"," \n","            with tf.GradientTape() as gp_tape:\n","                alpha = tf.random.uniform([batch_size],0.,1.,dtype=tf.float32)\n","                alpha = tf.reshape(alpha,(-1,1,1,1))\n","                sample_images = real_images + alpha * (fake_images - real_images)\n","\n","                gp_tape.watch(sample_images)\n","                sample_predictions = discriminator(sample_images, training=False)\n","                \n","            gradients = gp_tape.gradient(sample_predictions,sample_images)                \n","            grad_l2 = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1,2,3]))\n","            gradient_penalty = tf.reduce_mean((grad_l2-1) ** 2)            \n","            discriminator_loss +=lam*gradient_penalty \n","\n","        discriminator_gradients = discriminator_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n","        generator_gradients = generator_tape.gradient(generator_loss, generator.trainable_variables)\n","\n","        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n","        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n","\n","        return(discriminator_loss, generator_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjhWlUDvLsRL","colab_type":"code","colab":{}},"source":["def generate_images():\n","      sample_z = tf.random.uniform(minval=-1,maxval=1, shape=(batch_size, z_dim), dtype=tf.dtypes.float32)\n","      generated_images = generator(sample_z, training=False)\n","      generated_images = generated_images.numpy()\n","      generated_images = generated_images.reshape(generated_images.shape[0], 28, 28).astype('float32')\n","      generated_images = (generated_images + 1.) / 2. * 255.\n","      generated_images = generated_images.astype('uint8')\n","      plot.imshow(generated_images[0])\n","      plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gq1w01st4EPq","colab_type":"code","colab":{}},"source":["for epoch in range(start_epoch, epochs):\n","  step = 1\n","  for batch_images, _ in train_dataset:\n","    discriminator_loss, generator_loss = train_one_step(batch_images)\n","\n","    if step % 100 == 0:\n","      generate_images()\n","      print('discriminator loss', discriminator_loss.numpy(), 'generator loss', generator_loss.numpy())\n","\n","    step = step + 1"],"execution_count":0,"outputs":[]}]}
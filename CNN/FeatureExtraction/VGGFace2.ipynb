{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGGFace2.ipynb","provenance":[{"file_id":"https://github.com/look4pritam/TensorFlowExamples/blob/master/CNN/FeatureExtraction/VGGFace2.ipynb","timestamp":1592746360029},{"file_id":"https://github.com/look4pritam/TensorFlowExamples/blob/master/CNN/FeatureExtraction/VGGFace2.ipynb","timestamp":1592706196880},{"file_id":"https://github.com/look4pritam/TensorFlowExamples/blob/master/CNN/FeatureExtraction/VGGFace2.ipynb","timestamp":1592655078225},{"file_id":"1TLoWY-qtjZxs1ENduq31XPZp0zB0zH82","timestamp":1591340829118}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JH7Z46TRjOfN","colab_type":"text"},"source":["# Check GPU version."]},{"cell_type":"code","metadata":{"id":"3gtroS-sjSOa","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLls6Lw8jay6","colab_type":"text"},"source":["# Mount google drive."]},{"cell_type":"code","metadata":{"id":"CrWdN-ItjeA-","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GanKpOKVCjl","colab_type":"text"},"source":["# Install TensorFlow-1.14 GPU."]},{"cell_type":"code","metadata":{"id":"KwU8LfwfTdKW","colab_type":"code","colab":{}},"source":["# Select TensorFlow-1.x version.\n","%tensorflow_version 1.x\n","\n","# Uninstall previous TensorFlow version.\n","!pip uninstall tensorflow -y 1>/dev/null 2>/dev/null \n","!pip uninstall tensorflow-gpu -y 1>/dev/null 2>/dev/null \n","\n","# Install TensorFlow-1.14 and Keras-2.2.4.\n","!pip install --upgrade tensorflow-gpu==1.14.0 1>/dev/null 2>/dev/null \n","!pip install --upgrade tensorflow==1.14.0 1>/dev/null 2>/dev/null \n","!pip install --upgrade keras==2.2.4 1>/dev/null 2>/dev/null "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1o9-2_Q5WB2L","colab_type":"text"},"source":["# Restart the runtime."]},{"cell_type":"markdown","metadata":{"id":"vhgcf2TojTrO","colab_type":"text"},"source":["# Set the root directory."]},{"cell_type":"code","metadata":{"id":"9OOolap6jT-y","colab_type":"code","colab":{}},"source":["import os\n","\n","root_dir = '/content/'\n","os.chdir(root_dir)\n","\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yO7qbt-JWLH3","colab_type":"text"},"source":["# Import TensorFlow-1.14."]},{"cell_type":"code","metadata":{"id":"fkBgJBpiWLyA","colab_type":"code","colab":{}},"source":["try:\n","  %tensorflow_version 1.x\n","except Exception:\n","  pass\n","\n","import numpy as np\n","np.random.seed(7)\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ejeceg2KB7N","colab_type":"text"},"source":["### Install keras_vggface module."]},{"cell_type":"code","metadata":{"id":"VjMOq2w8CmcH","colab_type":"code","colab":{}},"source":["!pip install keras_vggface 1>/dev/null 2>/dev/null "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ll4h4CDDO3NK","colab_type":"text"},"source":["### Download ResNet-50 model trained using VGG Face-2 dataset."]},{"cell_type":"code","metadata":{"id":"aMfM1ZdUjvhJ","colab_type":"code","colab":{}},"source":["image_shape = (224, 224, 3)\n","image_load_shape = (256, 256, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_kfEDPMFf0s","colab_type":"code","colab":{}},"source":["aligned_image_dir = '/content/drive/My Drive/aligned_images/'\n","test_image_dir = '/content/drive/My Drive/test_images/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YbxcIwytR8j7","colab_type":"text"},"source":["# Create ResNet-50 (trained on VGG Face-2 dataset) based feature extractor."]},{"cell_type":"code","metadata":{"id":"X65tE1V2mvJU","colab_type":"code","colab":{}},"source":["from keras_vggface.vggface import VGGFace\n","\n","model = VGGFace(model='resnet50', include_top=False, input_shape=image_shape, pooling='avg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XA7K1hz3YHmW","colab_type":"text"},"source":["### Normalize input image."]},{"cell_type":"code","metadata":{"id":"oqNe0BP_uTwh","colab_type":"code","colab":{}},"source":["from keras_vggface import utils\n","\n","def normalize_image(image_filename): \n","  input_image = image.load_img(image_filename, target_size=(image_shape[0], image_shape[1])) \n","  output_image = image.img_to_array(input_image)\n","  output_image = np.expand_dims(output_image, axis=0) \n","  output_image = utils.preprocess_input(output_image, version=1)\n","  return( output_image )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_2QFep4YLg7","colab_type":"text"},"source":["### Compute image features."]},{"cell_type":"code","metadata":{"id":"o_LM0YWRA42p","colab_type":"code","colab":{}},"source":["def compute_image_features(model, image_filename): \n","  current_image = normalize_image(image_filename)\n","  current_features = model.predict(current_image)\n","  current_features = current_features[0]  \n","  current_features = current_features / np.linalg.norm(current_features)\n","  return( current_features )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOstt82lYQzS","colab_type":"text"},"source":["# Register persons using single image."]},{"cell_type":"code","metadata":{"id":"TYzP1TmFtR0b","colab_type":"code","colab":{}},"source":["from keras.preprocessing import image\n","\n","def compute_features(model, aligned_image_dir):\n","  image_features = {}\n","  image_filenames = os.listdir(aligned_image_dir)\n","  for image_filename in image_filenames:\n","    identifier = image_filename.split('.jpg')\n","    identifier = identifier[0]\n","\n","    image_path = os.path.join(aligned_image_dir, image_filename)\n","    current_features = compute_image_features(model, image_path)\n","\n","    image_features[identifier] = current_features\n","  return(image_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ2kEmjZwyH8","colab_type":"code","colab":{}},"source":["image_features = compute_features(model, aligned_image_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"snNcPEnRYaAN","colab_type":"text"},"source":["# Identify person using pre-computed image features."]},{"cell_type":"code","metadata":{"id":"gMBvszYZynjL","colab_type":"code","colab":{}},"source":["def identify_person(image_features, current_features, threshold=100):\n","  person_name = 'unknown'\n","  minimum_distance = float('inf')\n","\n","  for person in image_features:\n","    person_features = image_features[person]\n","    current_distance = np.linalg.norm(person_features - current_features)\n","\n","    if(current_distance < minimum_distance):\n","      minimum_distance = current_distance\n","      person_name = person\n","\n","  if(minimum_distance > threshold):\n","    person_name = 'unknown'\n","\n","  return(person_name, minimum_distance)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kwZYxjsyYgPg","colab_type":"text"},"source":["# Test one-shot recognition."]},{"cell_type":"code","metadata":{"id":"cJa52NBl7UsO","colab_type":"code","colab":{}},"source":["def identify_persons(image_features, test_image_dir):\n","  image_filenames = os.listdir(test_image_dir)\n","  for image_filename in image_filenames:\n","\n","    identifier = image_filename.split('.jpg')\n","    identifier = identifier[0]\n","\n","    image_path = os.path.join(test_image_dir, image_filename)\n","    current_features = compute_image_features(model, image_path)\n","    person_name, minimum_distance = identify_person(image_features, current_features)\n","    print('**************************************************')\n","    print('ground truth -', identifier)\n","    print('predicted -',person_name)\n","    print('distance -',minimum_distance)\n","    print('**************************************************')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RE_wDWrc77wU","colab_type":"code","colab":{}},"source":["identify_persons(model, image_features, test_image_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdwPNQLGpQjJ","colab_type":"text"},"source":["# Evaluate the model."]},{"cell_type":"markdown","metadata":{"id":"e5ulOF27pS5C","colab_type":"text"},"source":["### Download and extract aligned test dataset from goolge drive."]},{"cell_type":"code","metadata":{"id":"pxyGPej5pVpA","colab_type":"code","colab":{}},"source":["!gdown --id 1WEftISRMb-8v9iIFomzCzSAzbEvxOKFu # aligned_vggface2_test.tar.gz\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puHXj9eGpXzP","colab_type":"code","colab":{}},"source":["!tar -xzf aligned_vggface2_test.tar.gz\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t3P4zEypZuJ","colab_type":"code","colab":{}},"source":["!rm -rf aligned_vggface2_test.tar.gz\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2tMTQZspcG9","colab_type":"text"},"source":["### Check downloaded test dataset."]},{"cell_type":"code","metadata":{"id":"hzCwPy7EpeVc","colab_type":"code","colab":{}},"source":["!ls -al\n","!ls -l test/ | grep ^d | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-GImexfpj5L","colab_type":"text"},"source":["# Preprocess input image."]},{"cell_type":"code","metadata":{"id":"KpsBUg-1pmeF","colab_type":"code","colab":{}},"source":["def center_crop(input_image , target_size):\n","  target_height, target_width = target_size\n","  \n","  height_offset = (input_image.shape[0] - target_height) // 2 \n","  width_offset = (input_image.shape[1] - target_width) // 2 \n","\n","  targate_image = input_image[height_offset:(height_offset+target_height), width_offset:(width_offset+target_width) ]\n","  return(targate_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKnsQQ17poq4","colab_type":"code","colab":{}},"source":["import cv2\n","from keras_vggface import utils\n","\n","def preprocess_test_image(image_filename): \n","  input_image = cv2.imread(image_filename) \n","  input_image = cv2.resize(input_image, (image_load_shape[0], image_load_shape[1])) \n","  input_image = center_crop(input_image, (image_shape[0], image_shape[1]))  \n","  input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n","  input_image = input_image.astype(np.float)\n","  input_image = np.expand_dims(input_image, axis=0) \n","  input_image = utils.preprocess_input(input_image, version=1)\n","  return( input_image )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKXmHrraqUHM","colab_type":"text"},"source":["# Compute test image features."]},{"cell_type":"code","metadata":{"id":"sHSBO4cyqVCC","colab_type":"code","colab":{}},"source":["def compute_test_image_features(model, image_filename): \n","  current_image = preprocess_test_image(image_filename)\n","  current_features = model.predict(current_image)\n","  current_features = current_features[0]  \n","  current_features = current_features / np.linalg.norm(current_features)\n","  return( current_features )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RZrCHcbdqY8K","colab_type":"text"},"source":["### Evaluate the model on test dataset."]},{"cell_type":"code","metadata":{"id":"v782xoTKsLxt","colab_type":"code","colab":{}},"source":["test_image_dir = '/content/test/'\n","show_accuracy = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_ZSM7c9tL1q","colab_type":"code","colab":{}},"source":["minimum_similarity = 0.5\n","maximum_distance = 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwupgHlktdPM","colab_type":"code","colab":{}},"source":["separator = ' ,'\n","\n","verification_filename = 'vggface2_verification'\n","verification_file = open(verification_filename, 'w')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYsHQM39qbHr","colab_type":"code","colab":{}},"source":["class_names = os.listdir(test_image_dir)\n","number_of_images = 0\n","positive_distance_images = 0\n","positive_similarity_images = 0\n","for class_name in class_names:\n","  class_root_dir = os.path.join(test_image_dir, class_name)\n","  if(not os.path.isdir(class_root_dir)):\n","    continue\n","\n","  #print(class_name)\n","  image_filenames = os.listdir(class_root_dir)\n","  current_number_of_images = len(image_filenames)  \n","  image_index = np.random.randint(0, current_number_of_images)\n","\n","  base_image_filename = os.path.join(class_root_dir, image_filenames[image_index])  \n","  base_features = compute_test_image_features(model, base_image_filename)\n","\n","  for image_filename in image_filenames:\n","    current_image_filename = os.path.join(class_root_dir, image_filename)\n","    if(not os.path.isfile(current_image_filename)):\n","      continue\n","\n","    number_of_images = number_of_images + 1\n","    \n","    current_features = compute_test_image_features(model, current_image_filename)\n","\n","    current_distance = np.linalg.norm(base_features - current_features)    \n","    distance_status = current_distance < maximum_distance\n","    positive_distance_images = positive_distance_images + distance_status\n","\n","    current_similarity = np.dot(base_features, np.transpose(current_features))\n","    similarity_status = current_similarity > minimum_similarity\n","    positive_similarity_images = positive_similarity_images + similarity_status\n","\n","    verification_file.write(base_image_filename \n","                            + separator + current_image_filename \n","                            + separator + str(current_distance)\n","                            + separator + str(current_similarity)\n","                            + os.linesep)\n","    \n","    #print(current_similarity)\n","    \n","    if show_accuracy and (number_of_images % 1000 == 0):\n","      print('accuracy (distance) - ', positive_distance_images/number_of_images)\n","      print('accuracy (similarity) - ', positive_similarity_images/number_of_images)\n","  \n","verification_file.close()\n","print('accuracy (distance) - ', positive_distance_images/number_of_images)\n","print('accuracy (similarity) - ', positive_similarity_images/number_of_images)"],"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/look4pritam/ArtificialIntelligence/blob/master/ConvolutionalNeuralNetwork/Notebooks/TransferLearning/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Vi_RFldc9V"
      },
      "source": [
        "# Image Classification using Convolutional Neural Network\n",
        "\n",
        "In this example, we will learn to classify images using [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network). \n",
        "\n",
        "We will use TensorFlow flower dataset for classification. \n",
        "\n",
        "See [link](https://www.tensorflow.org/datasets/catalog/tf_flowers) for more details on the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the root directory for processing."
      ],
      "metadata": {
        "id": "MGqrHf5ZQOC2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExtT7EOj_X8D"
      },
      "source": [
        "import os\n",
        "\n",
        "root_dir = '/content/'\n",
        "os.chdir(root_dir)\n",
        "\n",
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required python modules."
      ],
      "metadata": {
        "id": "_lhXc1taRnGs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGkBi5d_MDt"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(7)"
      ],
      "metadata": {
        "id": "K51SsXs0jbiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Oxford flowers-102 dataset using TensorFlow dataset."
      ],
      "metadata": {
        "id": "pfwutdfBWucD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required python modules."
      ],
      "metadata": {
        "id": "kWQMAqjmYcUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "W6q5uhlkYczY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a dataset name and dataset splits."
      ],
      "metadata": {
        "id": "RPSCY0FoW5n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'oxford_flowers102'\n",
        "splits = ['test', 'validation', 'train']"
      ],
      "metadata": {
        "id": "UjzO6AtjkFx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset."
      ],
      "metadata": {
        "id": "gVNypODBW_wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, dataset_info = tfds.load(dataset_name, split = splits, with_info=True, as_supervised=True)\n",
        "(train_samples, validation_samples, test_samples) = dataset"
      ],
      "metadata": {
        "id": "qq9Htm8oXGgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show information about the dataset."
      ],
      "metadata": {
        "id": "JUuKnZ2HX1uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of flower types - ', dataset_info.features['label'].num_classes)\n",
        "print('Number of training examples - ', tf.data.experimental.cardinality(train_samples))\n",
        "print('Number of validation examples - ', tf.data.experimental.cardinality(validation_samples))\n",
        "print('Number of test examples - ', tf.data.experimental.cardinality(test_samples))\n",
        "\n",
        "print('Flower types full list is as follows - ')\n",
        "print(dataset_info.features['label'].names)"
      ],
      "metadata": {
        "id": "Sg36r6hhkMG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the dataset information."
      ],
      "metadata": {
        "id": "YtjkJPR3cVJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_info)"
      ],
      "metadata": {
        "id": "JeQ8CYA_mF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show dataset samples."
      ],
      "metadata": {
        "id": "OAe8bQVwX79p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfds.show_examples(train_samples, dataset_info, rows=2, cols=8)"
      ],
      "metadata": {
        "id": "KPs7-Q22X8e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process the dataset."
      ],
      "metadata": {
        "id": "eFy9kmQhaJE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the image size and the model shape."
      ],
      "metadata": {
        "id": "VASvMtbuaMgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "model_shape = (image_size, image_size, 3)"
      ],
      "metadata": {
        "id": "nc1_ypYrlBd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a function to format samples."
      ],
      "metadata": {
        "id": "66lbwDJGaf4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_sample(input_image, input_label):\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    input_image = input_image / 255.0\n",
        "\n",
        "    input_image = tf.image.resize(input_image, (image_size, image_size))\n",
        "\n",
        "    return(input_image, input_label)"
      ],
      "metadata": {
        "id": "jnXvZRe7lInE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format train, validation, and test samples."
      ],
      "metadata": {
        "id": "BECZLkB5a9Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_samples.map(format_sample)\n",
        "validation_dataset = validation_samples.map(format_sample)\n",
        "test_dataset = test_samples.map(format_sample)"
      ],
      "metadata": {
        "id": "OKDwrvYgudn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a function to augment the train dataset."
      ],
      "metadata": {
        "id": "V9Ypec_NbDhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(image, label):\n",
        "\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.random_contrast(image, lower=0.0, upper=1.0)\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "Xi5N7wJaltkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augment the train dataset."
      ],
      "metadata": {
        "id": "zrdse--ybKpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(augment_data)"
      ],
      "metadata": {
        "id": "ok2eD724bRNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a buffer size and a batch size for processing the dataset."
      ],
      "metadata": {
        "id": "G19pHRXbbVFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 1024\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "u9dsjR2Vbcu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the train datasset."
      ],
      "metadata": {
        "id": "sQ0-IIvtbe_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "dk7n6LQRbjtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the validation dataset."
      ],
      "metadata": {
        "id": "rKfExNlObu3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = validation_dataset.batch(batch_size)\n",
        "validation_dataset = validation_dataset.repeat()\n",
        "\n",
        "print(validation_dataset)"
      ],
      "metadata": {
        "id": "Md5Ux6PJbyOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the test dataset."
      ],
      "metadata": {
        "id": "UTrmCTXBb7SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.repeat()\n",
        "\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "id": "IbxGXReQl3t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a CNN based classification model for training from scratch."
      ],
      "metadata": {
        "id": "qcFcJFrPSUWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required python modules."
      ],
      "metadata": {
        "id": "MKZ6ckzvchM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D"
      ],
      "metadata": {
        "id": "ySpRl0jYSRh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use MobileNetV2 model for training."
      ],
      "metadata": {
        "id": "1rcl34R5cqHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.MobileNetV2(input_shape=model_shape, include_top=False, weights=None) #weights='imagenet')"
      ],
      "metadata": {
        "id": "6CtIaJNsStxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show model summary."
      ],
      "metadata": {
        "id": "bqtH2HCic0-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "tzUSCNwi7vfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model for image classification."
      ],
      "metadata": {
        "id": "dcLsjmwLc7dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    \n",
        "    input_image = base_model.input\n",
        "\n",
        "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    predictions = keras.layers.Dense(dataset_info.features['label'].num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_image, outputs=predictions)   \n",
        "\n",
        "    return (model)"
      ],
      "metadata": {
        "id": "BmTy-o3j8cUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create image classification model and show the summary."
      ],
      "metadata": {
        "id": "8LPyh0iNdBPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uBECsa1V9Dvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "6TyYskD1Sye6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyFBjiKyAq-F"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a callback function."
      ],
      "metadata": {
        "id": "jp_Mzn7GTc6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
      ],
      "metadata": {
        "id": "wTN6hEwlUQkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model."
      ],
      "metadata": {
        "id": "M2h2sk6JTunB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define number of steps for train, validation, and test dataset."
      ],
      "metadata": {
        "id": "1FQkKXY2gXGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = round(tf.data.experimental.cardinality(train_samples).numpy())//batch_size\n",
        "validation_steps = round(tf.data.experimental.cardinality(validation_samples).numpy())//batch_size\n",
        "test_steps = round(tf.data.experimental.cardinality(test_samples).numpy())//batch_size"
      ],
      "metadata": {
        "id": "A1gWeuDroDIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define number of epochs."
      ],
      "metadata": {
        "id": "RQhn6zJ-gSAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "iubEHddvT9jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model."
      ],
      "metadata": {
        "id": "VZxKr4Nsg_tH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcYZMXNMmOF"
      },
      "source": [
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=validation_dataset, \n",
        "                    validation_steps=validation_steps,\n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs,\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the trained model."
      ],
      "metadata": {
        "id": "0ruZjcKVUqOn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9haISXdT_Ors"
      },
      "source": [
        "evaluation_data = model.evaluate(test_dataset, steps=test_steps)\n",
        "print('Test loss - {0:.4f}'.format(evaluation_data[0]))\n",
        "print('Test accuracy - {0:.4f}'.format(evaluation_data[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize training graphs."
      ],
      "metadata": {
        "id": "9A_McnLpUlO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "f8SyFYhPUnEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}